---
title: "Logistic_model"
author: "Chloe Florence"
date: "2025-10-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
red_wine <- read.csv("winequality-red.csv", header = TRUE, sep = ";")
red_wine["type"] = 1
white_wine <- read.csv("winequality-white.csv", header = TRUE, sep = ";")
white_wine["type"] = 0
wine <- bind_rows(red_wine, white_wine)
wine$good <- ifelse(wine$quality > 5, 1, 0)
```


# Logistic Model

```{r}
set.seed(1)
train <- sample(6497, 5198)

log_mod <- glm(good ~ . - quality, data = wine, family = binomial, subset = train)
summary(log_mod)
```

```{r}
library(bestglm)

model <- bestglm(wine[train,-12], IC="BIC")
model
```



```{r}
library(leaps)
regfit.fwd = regsubsets(good ~ . - quality,data = wine, subset = train)
summary(regfit.fwd)
```



```{r}
log_mod <- glm(good ~ volatile.acidity + residual.sugar + free.sulfur.dioxide + total.sulfur.dioxide + sulphates + alcohol, data = wine, family = binomial, subset = train)
summary(log_mod)
```


## finding the test error

```{r}
test<- wine[-train,]
glm.probs <- predict(log_mod, test , type = "response")

glm.pred <- rep(0, 1299)
glm.pred[glm.probs > .5] <- 1

table(glm.pred, test$good)

mean(glm.pred != test$good)
```

The test error in this case was 25.096%

## Cross Validation - all this wrong get rid of this

We will be training the data on 4/5ths of the data and then using the remaining 1/5 to test the data. The cross validation error will be the mean of the 5 different test errors we will get.

```{r}
# getting the 5 different samples
set.seed(1)
a <- sample(1:6497, 1299)
b <- sample(setdiff(1:6497, a), 1299)
c <- sample(setdiff(1:6497, c(a, b)), 1299)
d <- sample (setdiff(1:6497, c(a, b, c)), 1300)
e <- setdiff(1:6497, c(a, b, c, d))
```


```{r}
library(pROC)
samples <- list(a = a,b = b,c = c,d = d,e = e)
error <- c()
for (i in 1:5){
  # model for this training data set
  test <- samples[[i]]
  train <- setdiff(1:nrow(wine), test)
  log_mod <- glm(good ~ volatile.acidity + residual.sugar + free.sulfur.dioxide + total.sulfur.dioxide + sulphates + alcohol, data = wine, family = binomial, subset = train)
  glm.probs <- predict(log_mod, wine[test,], type = "response")
  
  glm.pred <- ifelse(glm.probs > 0.5, 1, 0)
  
  actual <- wine$good[test]
  new_err <- mean(glm.pred != actual)
  #print(table(glm.pred, actual))
  
  error <- c(error, new_err)
  
  roc_obj <- roc(actual, glm.pred)
  plot(roc_obj, main = "ROC Curve",xlab = "False Positive Rate (1 - Specificity)", 
         ylab = "True Positive Rate (Sensitivity)")
}

error
mean(error)
```

accuracy = 1 - 0.26227 = 0.73773 ~ 73.77% accurate

Precision Average = 0.766588708513

This means on average 76.65% of the true positive are correct out of the total predicted positive.

Recall: 0.841987326462

This means on average 84.12% of the true positive are correct out of the total true positive. 


## full model

```{r}
full_mod <- log_mod <- glm(good ~ volatile.acidity + residual.sugar + free.sulfur.dioxide + total.sulfur.dioxide + sulphates + alcohol, data = wine, family = binomial)
summary(full_mod)
```


```{r}
plot(wine$residual.sugar + wine$free.sulfur.dioxide +wine$volatile.acidity,wine$free.sulfur.dioxide +wine$sulphates + wine$alcohol)
```


```{r}
wine[wine$residual.sugar + wine$free.sulfur.dioxide +wine$volatile.acidity > 200,]
```

```{r}
par(mfrow = c(2, 3))

boxplot(wine$volatile.acidity, wine$good, xlab = "Volatile Acidity", ylab = "Wine Quality")

boxplot(wine$residual.sugar, wine$good, xlab = "Residual Sugar", ylab = "Wine Quality")

boxplot(wine$total.sulfur.dioxide, wine$good, xlab = "Total Sulfur Dioxide", ylab = "Wine Quality")

boxplot(wine$free.sulfur.dioxide, wine$good, xlab = "Free Sulfur Dioxide", ylab = "Wine Quality")

boxplot(wine$sulphates, wine$good, xlab = "Sulphates", ylab = "Wine Quality")

boxplot(wine$alcohol, wine$good, xlab = "Alcohol", ylab = "Wine Quality")
```
















