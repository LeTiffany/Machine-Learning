---
title: "Logistic_model"
author: "Chloe Florence"
date: "2025-10-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
red_wine <- read.csv("winequality-red.csv", header = TRUE, sep = ";")
red_wine["type"] = 1
white_wine <- read.csv("winequality-white.csv", header = TRUE, sep = ";")
white_wine["type"] = 0
wine <- bind_rows(red_wine, white_wine)
wine$good <- ifelse(wine$quality > 5, 1, 0)
```


# Logistic Model

```{r}
set.seed(1)
train <- sample(6497, 5198)


log_mod <- glm(good ~ . - quality, data = wine, family = binomial, subset = train)
summary(log_mod)
```


```{r}
library(leaps)
regfit.fwd = regsubsets(good ~ . - quality,data = wine, subset = train)
summary(regfit.fwd)
```

```{r}
library(bestglm)
model <- bestglm(wine[train,-12], IC="BIC")
model
```

```{r}
log_mod <- glm(good ~ volatile.acidity + residual.sugar + free.sulfur.dioxide + total.sulfur.dioxide + sulphates + alcohol, data = wine, family = binomial, subset = train)
summary(log_mod)
```


## finding the test error

```{r}
test<- wine[-train,]
glm.probs <- predict(log_mod, test , type = "response")

glm.pred <- rep(0, 1299)
glm.pred[glm.probs > .5] <- 1

table(glm.pred, test$good)

mean(glm.pred != test$good)
```

The test error in this case was 25.096%

## Cross Validation

We will be training the data on 4/5ths of the data and then using the remaining 1/5 to test the data. The cross validation error will be the mean of the 5 different test errors we will get.

```{r}
# getting the 5 different samples
set.seed(1)
a <- sample(1:6497, 1299)
b <- sample(setdiff(1:6497, a), 1299)
c <- sample(setdiff(1:6497, c(a, b)), 1299)
d <- sample (setdiff(1:6497, c(a, b, c)), 1300)
e <- setdiff(1:6497, c(a, b, c, d))
```


```{r}
library(pROC)
samples <- list(a = a,b = b,c = c,d = d,e = e)
error <- c()
for (i in 1:5){
  # model for this training data set
  test <- samples[[i]]
  train <- setdiff(1:nrow(wine), test)
  log_mod <- glm(good ~ volatile.acidity + residual.sugar + free.sulfur.dioxide + total.sulfur.dioxide + sulphates + alcohol, data = wine, family = binomial, subset = train)
  glm.probs <- predict(log_mod, wine[test,], type = "response")
  
  glm.pred <- ifelse(glm.probs > 0.5, 1, 0)
  
  actual <- wine$good[test]
  new_err <- mean(glm.pred != actual)
  #print(table(glm.pred, actual))
  
  error <- c(error, new_err)
  
  roc_obj <- roc(actual, glm.pred)
  plot(roc_obj, main = "ROC Curve",xlab = "False Positive Rate (1 - Specificity)", 
         ylab = "True Positive Rate (Sensitivity)")
}

error
mean(error)
```

accuracy = 1 - 0.26227 = 0.73773 ~ 73.77% accurate

Precision Average = 0.766588708513

This means on average 76.65% of the true positive are correct out of the total predicted positive.

Recall: 0.841987326462

This means on average 84.12% of the true positive are correct out of the total true positive. 


## full model

```{r}
full_mod <- log_mod <- glm(good ~ volatile.acidity + residual.sugar + free.sulfur.dioxide + total.sulfur.dioxide + sulphates + alcohol, data = wine, family = binomial)
summary(full_mod)
```





















